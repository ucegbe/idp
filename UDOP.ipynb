{
 "cells": [  
  {
   "cell_type": "markdown",
   "id": "b066120a-d51d-4b2f-977e-1b750e77cc75",
   "metadata": {},
   "source": [
    "### Extract document using Textract Synchronous Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4ad3a22a-2603-4817-9cbc-7b958a08e320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "\n",
    "def detect_words_in_document(document_path):\n",
    "    # Initialize the AWS Textract client\n",
    "    textract = boto3.client('textract')\n",
    "\n",
    "    # Check if the document_path is an S3 path\n",
    "    if document_path.startswith('s3://'):\n",
    "        # Parse the S3 path\n",
    "        s3_pattern = r's3://(?P<bucket>[^/]+)/(?P<key>.+)'\n",
    "        match = re.match(s3_pattern, document_path)\n",
    "        if not match:\n",
    "            raise ValueError(\"Invalid S3 path format. Use 's3://bucket-name/path/to/document'\")\n",
    "\n",
    "        bucket_name = match.group('bucket')\n",
    "        object_key = match.group('key')\n",
    "\n",
    "        # Prepare S3 document for Textract\n",
    "        document = {'S3Object': {'Bucket': bucket_name, 'Name': object_key}}\n",
    "    else:\n",
    "        # Handle local file\n",
    "        with open(document_path, 'rb') as file:\n",
    "            file_bytes = file.read()\n",
    "        document = {'Bytes': file_bytes}\n",
    "\n",
    "    # Call the Detect Document Text API\n",
    "    response = textract.detect_document_text(Document=document)\n",
    "\n",
    "    # Initialize lists to store words, bounding boxes, and confidence scores\n",
    "    words = []\n",
    "    bboxes = []\n",
    "    confidence_scores = []\n",
    "\n",
    "    # Process the results\n",
    "    for block in response['Blocks']:\n",
    "        if block['BlockType'] == 'WORD':\n",
    "            words.append(block['Text'])\n",
    "\n",
    "            # Extract and format bounding box\n",
    "            bbox = block['Geometry']['BoundingBox']\n",
    "            left = int(bbox['Left'] * 1000)\n",
    "            top = int(bbox['Top'] * 1000)\n",
    "            right = int((bbox['Left'] + bbox['Width']) * 1000)\n",
    "            bottom = int((bbox['Top'] + bbox['Height']) * 1000)\n",
    "            bboxes.append([left, top, right, bottom])\n",
    "\n",
    "            confidence_scores.append(block['Confidence'])\n",
    "\n",
    "    return words, bboxes, confidence_scores\n",
    "\n",
    "# Example usage\n",
    "document_path = file\n",
    "words, bboxes, confidence_scores = detect_words_in_document(document_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177bee02-8ef0-4dcc-94eb-8b8bd0167d6b",
   "metadata": {},
   "source": [
    "## Create SageMaker Serverless Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "87bc4b5c-52f5-410a-9889-f912265a4a27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.serverless import ServerlessInferenceConfig\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "# Get the execution role\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "# Model artifacts and code configuration\n",
    "model_data = 's3://fairstone/output/churn-train-2024-05-01-01-57-13-054/output/model.tar.gz'  # Replace with your model artifacts path\n",
    "entry_point = 'inference.py'\n",
    "\n",
    "# Create PyTorch Model\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    source_dir='source',\n",
    "    entry_point=entry_point,\n",
    "    framework_version='2.1.0',\n",
    "    py_version='py310',\n",
    "    \n",
    ")\n",
    "\n",
    "# Specify MemorySizeInMB and MaxConcurrency in the serverless config object\n",
    "serverless_config = ServerlessInferenceConfig(\n",
    "    memory_size_in_mb=4096,\n",
    "    max_concurrency=10,\n",
    ")\n",
    "\n",
    "# Deploy the endpoint\n",
    "predictor = pytorch_model.deploy(\n",
    "    serverless_inference_config=serverless_config,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3cc2ab-9ce7-4227-9cd3-2cac116680df",
   "metadata": {},
   "source": [
    "## Invoke the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1ddbf6e3-acca-48ef-a50a-01af474a82d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.4 ms, sys: 149 Âµs, total: 6.55 ms\n",
      "Wall time: 4.76 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'result': '12/10/98'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "input_data = {\n",
    "    \"image\": encoded_image,\n",
    "    \"question\": \"Question answering. What is the date on the form?\",\n",
    "   \"words\" : words,\n",
    "\"boxes\":bboxes\n",
    "}\n",
    "predictor.predict(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe044da-4860-43d3-aa13-c2bfed24764b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bedrock Image Few Shot Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f6ee0e2b-7f8a-4ab1-a928-917c2c9eead4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the bedrock runtime to invoke LLM\n",
    "from botocore.config import Config\n",
    "import json\n",
    "import base64\n",
    "import time\n",
    "config = Config(\n",
    "    connect_timeout= 600, # Connection timeout parameter in seconds\n",
    "    read_timeout=600, # Read timeout parameter in seconds\n",
    "    retries = dict(\n",
    "        max_attempts = 10 ## Handle retries\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "import boto3\n",
    "bedrock_runtime = boto3.client(service_name='bedrock-runtime',region_name=\"us-west-2\",config=config) # change to your default region (us-west-2 is faster for Claude models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6137beeb-1254-476a-99d6-2836a6cdf86d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bedrock_streemer(response,model, stream=False):\n",
    "    if stream:\n",
    "        text=''\n",
    "        for chunk in response['stream']:       \n",
    "\n",
    "            if 'contentBlockDelta' in chunk:\n",
    "                delta = chunk['contentBlockDelta']['delta']       \n",
    "                if 'text' in delta:\n",
    "                    text += delta['text']               \n",
    "                    print(delta['text'] , end=\"\")\n",
    "\n",
    "            elif \"metadata\" in chunk:\n",
    "                input_tokens=chunk['metadata']['usage'][\"inputTokens\"]\n",
    "                output_tokens=chunk['metadata']['usage'][\"outputTokens\"]\n",
    "                latency=chunk['metadata']['metrics'][\"latencyMs\"]        \n",
    "                print(f\"\\nInput Tokens: {input_tokens}\\nOutput Tokens: {output_tokens}\\nLatency: {latency}ms\")\n",
    "    else:\n",
    "        \n",
    "        text=response['output']['message']['content'][0]['text']\n",
    "        token_usage = response['usage']\n",
    "        input_tokens=token_usage['inputTokens']\n",
    "        output_tokens=token_usage['outputTokens']\n",
    "        latency=response['metrics']['latencyMs'] \n",
    "        print(f\"Response:\\n{text}\\nInput Tokens: {input_tokens}\\nOutput Tokens: {output_tokens}\\nLatency: {latency}ms\")       \n",
    "      \n",
    "    return text, input_tokens,output_tokens, latency\n",
    "\n",
    "def bedrock_claude_(chat_history,system_message, prompt,model_id,stream=False,image_path=None):\n",
    "    chat_history_copy = chat_history[:]\n",
    "    content=[]\n",
    "    if image_path:\n",
    "        if not isinstance(image_path, list):\n",
    "            image_path = [image_path]\n",
    "\n",
    "        for ids,img in enumerate(image_path):\n",
    "            image_name = os.path.basename(img)\n",
    "            _, ext = os.path.splitext(image_name)\n",
    "            if \"jpg\" in ext: ext = \".jpeg\"\n",
    "\n",
    "            if img.startswith(\"s3://\"):\n",
    "                # Handle S3 images\n",
    "                s3 = boto3.client('s3', region_name=\"us-east-1\")\n",
    "                match = re.match(\"s3://(.+?)/(.+)\", img)\n",
    "                bucket_name = match.group(1)\n",
    "                key = match.group(2)\n",
    "                obj = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "                bytes_image = obj['Body'].read()\n",
    "            else:\n",
    "                # Handle local images\n",
    "                with open(img, 'rb') as image_file:\n",
    "                    bytes_image = image_file.read()\n",
    "            \n",
    "            content.extend([{\"text\":f\"IMAGE {ids+1}({image_name}):\"},{\n",
    "              \"image\": {\n",
    "                \"format\": f\"{ext.lower().replace('.','')}\",\n",
    "                \"source\": {\"bytes\":bytes_image}\n",
    "              }\n",
    "            }])\n",
    "\n",
    "    content.append({       \n",
    "        \"text\": prompt\n",
    "            })\n",
    "    chat_history_copy.append({\"role\": \"user\",\n",
    "            \"content\": content})\n",
    "    system_message=[{\"text\":system_message}]\n",
    "    if stream:\n",
    "        response = bedrock_runtime.converse_stream(messages=chat_history_copy, modelId=model_id,inferenceConfig={\"maxTokens\": 2000, \"temperature\": 0.5,},system=system_message)\n",
    "    else:\n",
    "        response = bedrock_runtime.converse(messages=chat_history_copy, modelId=model_id,inferenceConfig={\"maxTokens\": 2000, \"temperature\": 0.5,},system=system_message)\n",
    "\n",
    "    answer,input_tokens,output_tokens, latency=bedrock_streemer(response, model_id, stream) \n",
    "    return answer,input_tokens,output_tokens, latency\n",
    "\n",
    "\n",
    "def image_bytes_get(image_path):\n",
    "    \"\"\"\n",
    "    Function to create the few shot image examples\n",
    "    \"\"\"\n",
    "    content=[]\n",
    "    if not isinstance(image_path,dict):\n",
    "         raise ValueError(\"Input must be in Dictionary format\")\n",
    "    else:\n",
    "        for key,img in image_path.items():\n",
    "            image_name = os.path.basename(img)\n",
    "            _, ext = os.path.splitext(image_name)\n",
    "            if \"jpg\" in ext: ext = \".jpeg\"\n",
    "\n",
    "            if img.startswith(\"s3://\"):\n",
    "                # Handle S3 images\n",
    "                s3 = boto3.client('s3', region_name=\"us-east-1\")\n",
    "                match = re.match(\"s3://(.+?)/(.+)\", img)\n",
    "                bucket_name = match.group(1)\n",
    "                key = match.group(2)\n",
    "                obj = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "                bytes_image = obj['Body'].read()\n",
    "            else:\n",
    "                # Handle local images\n",
    "                with open(img, 'rb') as image_file:\n",
    "                    bytes_image = image_file.read()\n",
    "            content.extend([{\n",
    "                \"role\":\"user\",\n",
    "                \"content\":[\n",
    "                        {\n",
    "                          \"image\": {\n",
    "                            \"format\": f\"{ext.lower().replace('.','')}\",\n",
    "                            \"source\": {\"bytes\":bytes_image}\n",
    "                                  }\n",
    "                        },\n",
    "                        {\"text\":\"What is this image?\"}\n",
    "                    ]            \n",
    "                },            \n",
    "\n",
    "                {\"role\":\"assistant\",\n",
    "                 \"content\":[{\n",
    "                     \"text\":key\n",
    "                 }]\n",
    "                }])\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "950fbea1-7ab3-43d4-996d-1703d2f13d16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This should be a dictionary of the images (local or S3) and the label description {'label description':'image_path'}\n",
    "\n",
    "few_shot={'This is a paystub':'images/5d945f376f89f101477294.jpg',\n",
    " 'This is a drivers license':'images/john-doc1.png',\n",
    " 'This is a bank statement':'images/Lab.com (1)0.PNG',\n",
    " 'This is a paystub':'images/5acf72145500c.jpg',\n",
    " 'This is a bank statement':'images/TemplateLab0.PNG',\n",
    " 'This is a W2':'images/W2_XL_input_clean_1001.jpg',\n",
    " 'This is a W2':'images/W2_XL_input_clean_1568.jpg'}\n",
    "\n",
    "# Create few shot examples structure\n",
    "few_shot_content=image_bytes_get(few_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2a0f5ece-8de8-4113-9814-ee59d5d4c406",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<label>\n",
      "other\n",
      "</label>\n",
      "\n",
      "Reason for assigning the label:\n",
      "This image does not match any of the provided labels (paystub, bank statement, W2, or driver's license). The document shown is a confidential facsimile transmission cover sheet from the Office of the Attorney General. It contains details such as fax numbers, sender information, and a confidentiality notice, which are not characteristic of the listed document types. The letterhead and official seal indicate it's a government document, specifically from the Attorney General's office, making it distinct from the financial and identification documents in the given labels.\n",
      "Input Tokens: 6163\n",
      "Output Tokens: 133\n",
      "Latency: 6046ms\n"
     ]
    }
   ],
   "source": [
    "# Prompt template \n",
    "question=\"\"\"I have provided you a list of labelled documents as examples. \n",
    "Analyze those images carefully. Then provide a label for the unlabeled image(s)\n",
    "\n",
    "<labels>\n",
    "Here is the possible lables:\n",
    "1. paystub\n",
    "2. bank statement\n",
    "3. W2\n",
    "4. drivers license\n",
    "</labels>\n",
    "\n",
    "Provide a lable for the unlabeled image(s) from the list of possible labels above. Each image must have a single label only. \n",
    "If an image does not fall into any of the possible lables provided, respond with 'other'\n",
    "Always provide your reason for labeling each image\n",
    "Format your response as:\n",
    "<label>\n",
    "image label\n",
    "</label>\n",
    "Reason for assigning the label\n",
    "\"\"\" # user prompt\n",
    "\n",
    "\n",
    "\n",
    "model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\" #\n",
    "image_path=[\"test.png\"] # list of images (local or s3), leave empty if not using images\n",
    "stream=True # Stream response or not\n",
    "system_message=\"Your are an expert at anlyzing images and pay attention to image details. Your task will be to classify images into a list of provided labels\"\n",
    "response,input_tokens, output_tokens, latency=bedrock_claude_(few_shot_content,system_message, question,model_id,stream,image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d83842d-9c70-4b95-a316-95afabde22cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.c5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
